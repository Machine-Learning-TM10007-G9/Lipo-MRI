{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7SXpaKwwGe5x"
      },
      "source": [
        "# TM10007 Assignment lipomas G9"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CiDn2Sk-VWqE",
        "outputId": "54c4c5bf-fc56-4f7b-ae67-33f82b676f8c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m32.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m43.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m31.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m60.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for ktml (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "# Run this to use from colab environment\n",
        "!pip install -q --upgrade git+https://github.com/Machine-Learning-TM10007-G9/Lipo-MRI.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zuSR7zcbNW0h"
      },
      "source": [
        "# **Data loading**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-NE_fTbKGe5z",
        "outputId": "91befb0c-64a8-446e-dcc4-d1378957d511"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The number of samples: 115\n",
            "The number of columns: 494\n"
          ]
        }
      ],
      "source": [
        "from worclipo.load_data import load_data\n",
        "\n",
        "data = load_data()\n",
        "print(f'The number of samples: {len(data.index)}')\n",
        "print(f'The number of columns: {len(data.columns)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Import important functions**"
      ],
      "metadata": {
        "id": "g8ivKj_yynDm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "mSI_faQPNW0i"
      },
      "outputs": [],
      "source": [
        "# General packages\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import datasets as ds\n",
        "import seaborn\n",
        "\n",
        "\n",
        "# Classifiers\n",
        "from sklearn import model_selection\n",
        "from sklearn import metrics\n",
        "from sklearn import feature_selection\n",
        "from sklearn import preprocessing\n",
        "from sklearn import neighbors\n",
        "from sklearn import svm\n",
        "from sklearn import decomposition"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Create X and Y**"
      ],
      "metadata": {
        "id": "eFLxHJ2Az70n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = data.iloc[:, 1:].values\n",
        "y = np.array(data['label'])"
      ],
      "metadata": {
        "id": "DtPbcpXFz7au"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Split the data**"
      ],
      "metadata": {
        "id": "JIfugNhPzDo5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data\n",
        "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.2, stratify=y)\n",
        "\n",
        "#print(len(X_train))\n",
        "#print(len(X_test))\n",
        "#print(len(y_train))\n",
        "#print(len(y_test))"
      ],
      "metadata": {
        "id": "TmcPnIBdzCG_"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Check for missing values**\n",
        "\n"
      ],
      "metadata": {
        "id": "6Th7iN-wiDCz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "missing_values = np.sum(np.isnan(X_train))\n",
        "\n",
        "print(\"Number of missing values:\",missing_values)"
      ],
      "metadata": {
        "id": "xz_YEZ4niOB0",
        "outputId": "a39b06b0-73b2-4aae-c090-8a3a09c8147e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of missing values: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Checking for outliers**\n",
        "Using the Z-score"
      ],
      "metadata": {
        "id": "6c9Rj_XInE6p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy import stats\n",
        "\n",
        "num_rows, num_cols = X_train.shape\n",
        "total_outliers = 0\n",
        "\n",
        "for i in range(num_cols):\n",
        "    z = np.abs(stats.zscore(X_train[:,i]))\n",
        "\n",
        "    threshold = 3\n",
        "    outliers = X_train[z > threshold, i]\n",
        "    total_outliers +=(len(outliers))\n",
        "\n",
        "print(f'Total number of outliers  = {total_outliers}/{num_rows*num_cols}')\n",
        "print(f'Avarage number of outliers per feature = {round(total_outliers/num_cols,2)}/{num_rows}')\n"
      ],
      "metadata": {
        "id": "mPIPeNp-nJTv",
        "outputId": "e4f1261b-fb8f-474f-bc8f-03f90767e3db",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of outliers  = 652/45356\n",
            "Avarage number of outliers per feature = 1.32/92\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Check if the data is normally distributed**\n",
        "Using the Kolmogorov Smirnov"
      ],
      "metadata": {
        "id": "u3RmZ5isz4Iw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "total_not_normal = 0\n",
        "p_threshold = 0.05\n",
        "\n",
        "for l in range(num_cols):\n",
        "    kstest_result = stats.kstest(X_train[:,l], 'norm')\n",
        "    if kstest_result.pvalue < p_threshold:\n",
        "        total_not_normal += 1\n",
        "\n",
        "print(f'Total features that are not normally distributed = {total_not_normal}/{num_cols}')\n"
      ],
      "metadata": {
        "id": "PB_LKu7Bz3Ul",
        "outputId": "fe755853-b42d-4ef2-8496-22f4a6dc9cba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total features that are not normally distributed = 492/493\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Scaling**\n",
        "Robust scaling because outliers and non Gaussian distribution"
      ],
      "metadata": {
        "id": "Ammb7jQ7RCPb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Scale the data to be normal\n",
        "scaler = preprocessing.RobustScaler()\n",
        "scaler.fit(X_train)\n",
        "X_train_scaled = scaler.transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "SjdjlpnSRGGd"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Cross-validation**"
      ],
      "metadata": {
        "id": "1AqAls9XifaR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize KFold cross-validator\n",
        "kf = model_selection.StratifiedKFold(n_splits=5)\n",
        "\n",
        "# Iterate over each fold\n",
        "for train_index, val_index in kf.split(X_train, y_train):\n",
        "    # Split data into train and validation sets for this fold\n",
        "    X_train_fold, X_val_fold = X_train_scaled[train_index], X_train_scaled[val_index]\n",
        "    y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]\n",
        "\n",
        "print(len(X_train_fold))\n",
        "print(len(X_val_fold))\n",
        "print(len(y_train_fold))\n",
        "print(len(y_val_fold))"
      ],
      "metadata": {
        "id": "CaWPtHtmimZS",
        "outputId": "1d4daa89-dc42-40b4-e317-de9cf83583bd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "74\n",
            "18\n",
            "74\n",
            "18\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "assignment.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
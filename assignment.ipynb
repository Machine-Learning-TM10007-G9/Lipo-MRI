{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7SXpaKwwGe5x"
      },
      "source": [
        "# TM10007 Assignment lipomas G9"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CiDn2Sk-VWqE",
        "outputId": "54c4c5bf-fc56-4f7b-ae67-33f82b676f8c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m32.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m43.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m31.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m60.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for ktml (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "# Run this to use from colab environment\n",
        "!pip install -q --upgrade git+https://github.com/Machine-Learning-TM10007-G9/Lipo-MRI.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zuSR7zcbNW0h"
      },
      "source": [
        "# **Data loading**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-NE_fTbKGe5z",
        "outputId": "91befb0c-64a8-446e-dcc4-d1378957d511"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The number of samples: 115\n",
            "The number of columns: 494\n"
          ]
        }
      ],
      "source": [
        "from worclipo.load_data import load_data\n",
        "\n",
        "data = load_data()\n",
        "print(f'The number of samples: {len(data.index)}')\n",
        "print(f'The number of columns: {len(data.columns)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Import important functions**"
      ],
      "metadata": {
        "id": "g8ivKj_yynDm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "mSI_faQPNW0i"
      },
      "outputs": [],
      "source": [
        "# General packages\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import datasets as ds\n",
        "import seaborn\n",
        "\n",
        "\n",
        "# Classifiers\n",
        "from sklearn import model_selection\n",
        "from sklearn import metrics\n",
        "from sklearn import feature_selection\n",
        "from sklearn import preprocessing\n",
        "from sklearn import neighbors\n",
        "from sklearn import svm\n",
        "from sklearn import decomposition"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Create X and Y**"
      ],
      "metadata": {
        "id": "eFLxHJ2Az70n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = data.iloc[:, 1:].values\n",
        "y = np.array(data['label'])"
      ],
      "metadata": {
        "id": "DtPbcpXFz7au"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Split the data**"
      ],
      "metadata": {
        "id": "JIfugNhPzDo5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data\n",
        "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.2, stratify=y)\n",
        "\n",
        "#print(len(X_train))\n",
        "#print(len(X_test))\n",
        "#print(len(y_train))\n",
        "#print(len(y_test))"
      ],
      "metadata": {
        "id": "TmcPnIBdzCG_"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Checks if all the data points are floats**\n",
        "Is 0.0 a missing value?"
      ],
      "metadata": {
        "id": "eccXHmAeb1OX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for row in X_train:\n",
        "  for col in row:\n",
        "    if not isinstance(col, float):\n",
        "        print(col)"
      ],
      "metadata": {
        "id": "4aVtVkv1dljh"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Check for missing values**\n",
        "\n"
      ],
      "metadata": {
        "id": "6Th7iN-wiDCz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "missing_values = np.sum(np.isnan(X_train))\n",
        "\n",
        "print(\"Number of missing values:\",missing_values)"
      ],
      "metadata": {
        "id": "xz_YEZ4niOB0",
        "outputId": "88d47038-d8a1-4f24-bc15-8978b8053911",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of missing values: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Check for duplicates**\n",
        "Can we assume that duplicates values are duplicates?"
      ],
      "metadata": {
        "id": "OGrob7DIZl6c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to find duplicate columns and delete them\n",
        "def delete_duplicate_columns(arr):\n",
        "    num_cols = arr.shape[1]\n",
        "    duplicate_columns = []\n",
        "    for i in range(num_cols):\n",
        "        for j in range(i + 1, num_cols):\n",
        "            if np.array_equal(arr[:, i], arr[:, j]):\n",
        "                duplicate_columns.append(j)  # Append index of the duplicate column\n",
        "    if duplicate_columns:\n",
        "        # Delete duplicate columns\n",
        "        arr_without_duplicates = np.delete(arr, duplicate_columns, axis=1)\n",
        "        return arr_without_duplicates\n",
        "    else:\n",
        "        return arr\n",
        "\n",
        "# Remove duplicate columns\n",
        "X_train_clean = delete_duplicate_columns(X_train)\n",
        "\n",
        "print(\"Number of columns in original array:\",X_train.shape[1])\n",
        "print(\"Number of columns after removal of duplicate columns:\",X_train_clean.shape[1])"
      ],
      "metadata": {
        "id": "nyEMNXijZ37p",
        "outputId": "ec1626bb-dc20-4a83-8e4a-5c06d82602fe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of columns in original array: 493\n",
            "Number of columns after removal of duplicate columns: 466\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Checking for outliers**\n",
        "Using the Z-score"
      ],
      "metadata": {
        "id": "6c9Rj_XInE6p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy import stats\n",
        "\n",
        "num_rows, num_cols = X_train_clean.shape\n",
        "total_outliers = 0\n",
        "\n",
        "for i in range(num_cols):\n",
        "    z = np.abs(stats.zscore(X_train_clean[:,i]))\n",
        "\n",
        "    threshold = 3\n",
        "    outliers = X_train_clean[z > threshold, i]\n",
        "    total_outliers +=(len(outliers))\n",
        "\n",
        "print(f'Total number of outliers  = {total_outliers}/{num_rows*num_cols}')\n",
        "print(f'Avarage number of outliers per feature = {round(total_outliers/num_cols,2)}/{num_rows}')\n"
      ],
      "metadata": {
        "id": "mPIPeNp-nJTv",
        "outputId": "71cf49a5-c8c0-4d35-a8bb-b9ee0e199640",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of outliers  = 628/42872\n",
            "Avarage number of outliers per feature = 1.35/92\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Check if the data is normally distributed**\n",
        "Using the Kolmogorov Smirnov"
      ],
      "metadata": {
        "id": "u3RmZ5isz4Iw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "total_not_normal = 0\n",
        "p_threshold = 0.05\n",
        "\n",
        "for l in range(num_cols):\n",
        "    kstest_result = stats.kstest(X_train_clean[:,l], 'norm')\n",
        "    if kstest_result.pvalue < p_threshold:\n",
        "        total_not_normal += 1\n",
        "\n",
        "print(f'Total features that are not normally distributed = {total_not_normal}/{num_cols}')\n"
      ],
      "metadata": {
        "id": "PB_LKu7Bz3Ul",
        "outputId": "df1478c6-01cb-4011-d4fc-48652cb2c6c3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total features that are not normally distributed = 465/466\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Scaling**\n",
        "Robust scaling because outliers and non Gaussian distribution"
      ],
      "metadata": {
        "id": "Ammb7jQ7RCPb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Scale the data to be normal\n",
        "scaler = preprocessing.RobustScaler()\n",
        "scaler.fit(X_train_clean)\n",
        "X_train_scaled = scaler.transform(X_train_clean)"
      ],
      "metadata": {
        "id": "SjdjlpnSRGGd"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Cross-validation**"
      ],
      "metadata": {
        "id": "1AqAls9XifaR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize KFold cross-validator\n",
        "kf = model_selection.StratifiedKFold(n_splits=5)\n",
        "\n",
        "# Iterate over each fold\n",
        "for train_index, val_index in kf.split(X_train_clean, y_train):\n",
        "    # Split data into train and validation sets for this fold\n",
        "    X_train_fold, X_val_fold = X_train_scaled[train_index], X_train_scaled[val_index]\n",
        "    y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]\n",
        "\n",
        "print(len(X_train_fold))\n",
        "print(len(X_val_fold))\n",
        "print(len(y_train_fold))\n",
        "print(len(y_val_fold))"
      ],
      "metadata": {
        "id": "CaWPtHtmimZS",
        "outputId": "7fe2f28a-ff01-43a9-cb07-07b35c99cbad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "74\n",
            "18\n",
            "74\n",
            "18\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Feature selection**"
      ],
      "metadata": {
        "id": "qNAjbYOLjx53"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Nnk7Nwdlj4WI"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "assignment.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}